#!/usr/bin/env bash
# Chief Wiggum - Worker orchestration runner
#
# Orchestrates workers for executing software engineering tasks. Uses the
# scheduler module for unified worker tracking, priority workers, and status display.
set -euo pipefail

WIGGUM_HOME="${WIGGUM_HOME:-$HOME/.claude/chief-wiggum}"
PROJECT_DIR="$(pwd)"
RALPH_DIR="${RALPH_DIR:-$PROJECT_DIR/.ralph}"

# Source shared libraries
source "$WIGGUM_HOME/lib/core/exit-codes.sh"
source "$WIGGUM_HOME/lib/core/defaults.sh"
source "$WIGGUM_HOME/lib/core/verbose-flags.sh"
source "$WIGGUM_HOME/lib/core/logger.sh"
source "$WIGGUM_HOME/lib/core/file-lock.sh"
source "$WIGGUM_HOME/lib/utils/audit-logger.sh"
source "$WIGGUM_HOME/lib/utils/activity-log.sh"
source "$WIGGUM_HOME/lib/worker/worker-lifecycle.sh"
source "$WIGGUM_HOME/lib/worker/git-state.sh"
source "$WIGGUM_HOME/lib/claude/usage-tracker.sh"
source "$WIGGUM_HOME/lib/git/worktree-helpers.sh"
source "$WIGGUM_HOME/lib/tasks/task-parser.sh"
source "$WIGGUM_HOME/lib/tasks/plan-parser.sh"
source "$WIGGUM_HOME/lib/tasks/conflict-detection.sh"

# Source scheduler module (unified worker management)
source "$WIGGUM_HOME/lib/scheduler/scheduler.sh"
source "$WIGGUM_HOME/lib/scheduler/conflict-queue.sh"
source "$WIGGUM_HOME/lib/scheduler/conflict-registry.sh"
source "$WIGGUM_HOME/lib/scheduler/pr-merge-optimizer.sh"
source "$WIGGUM_HOME/lib/scheduler/orchestrator-functions.sh"

# Service-based scheduler (consolidated module includes core + state)
source "$WIGGUM_HOME/lib/service/service-scheduler.sh"
# Service handlers (svc_* functions callable via services.json)
source "$WIGGUM_HOME/lib/services/orchestrator-handlers.sh"

# Default configuration
MAX_WORKERS=4
MAX_ITERATIONS=20       # Max outer loop iterations per worker
MAX_TURNS=50           # Max turns per Claude session
AGENT_TYPE="system.task-worker"  # Default agent type (can be overridden with 'plan' mode)
PID_WAIT_TIMEOUT=300   # Deciseconds to wait for agent.pid (30 seconds)
FORCE_LOCK=false       # --force flag state for lock override
MAX_SKIP_RETRIES=3     # Kanban update failures before permanent skip
FIX_WORKER_TIMEOUT=1800  # Fix worker max runtime (seconds)
FIX_WORKER_LIMIT=""    # Max concurrent fix workers (loaded from config or CLI)
RESOLVE_WORKER_TIMEOUT=1800  # Resolve worker max runtime (seconds)
AGING_FACTOR=7         # Scheduling events per priority level promotion
SIBLING_WIP_PENALTY=20000  # Fixed-point penalty when sibling is WIP (20000 = 2.0)
PLAN_BONUS=15000           # Fixed-point bonus for tasks with plans (15000 = 1.5)
DEP_BONUS_PER_TASK=7000    # Fixed-point bonus per task blocked (7000 = 0.7)

show_help() {
    cat << EOF
wiggum run - Orchestrate workers for incomplete tasks

Usage: wiggum run [mode] [options]

Modes:
  (default)            Use system.task-worker agent (standard execution)
  plan                 Use system.task-worker agent with plan mode enabled (creates
                       implementation plan before execution)

Options:
  --max-workers N      Maximum concurrent workers (default: 4)
  --max-iters N        Maximum iterations per worker (default: 20)
  --max-turns N        Maximum turns per Claude session (default: 50)
  --fix-agents N       Maximum concurrent fix/resolve workers (default: 2, or config)
  --pipeline NAME      Pipeline config to use (from config/pipelines/ or config/)
  --force              Override stale orchestrator lock
  -v, --verbose        Verbose output (same as default)
  -vv                  Debug output (detailed diagnostics)
  -vvv                 Trace output (very detailed tracing)
  -q, --quiet          Quiet mode (warnings and errors only)
  -h, --help           Show this help message

Examples:
  wiggum run                              # Start orchestration with defaults
  wiggum run plan                         # Use planning mode for all workers
  wiggum run --max-workers 8              # Start with max 8 workers
  wiggum run plan --max-workers 2         # Planning mode with 2 workers
  wiggum run --pipeline fast              # Use the fast pipeline

Behavior:
  - Chief assigns pending tasks [ ] to workers based on dependency graph
  - Tasks are scheduled by priority: HIGH > MEDIUM > LOW
  - Tasks with unsatisfied dependencies are blocked until deps complete
  - Tasks are marked in-progress [=] when assigned
  - Workers mark tasks pending approval [P] when PR is created
  - Periodic sync updates [P] -> [x] when PRs are merged
  - Chief waits until all tasks are complete [x]
  - New workers spawn as old ones finish (up to max)
  - Circular dependencies are detected and reported at startup

Task resumption:
  - WIP tasks [=] with stopped workers are auto-resumed (if no worker is running)
  - Failed tasks [*] wait for manual intervention (use 'wiggum resume/retry')
  - Pending tasks [ ] with existing PRs go through fix pipeline (sync→fix→push→merge)

Logging:
  - Output is written to both stdout and .ralph/logs/orchestrator.log
  - Worker logs are in .ralph/logs/workers.log
  - Use 'tail -f .ralph/logs/orchestrator.log' to follow in another terminal

EOF
}

# Spawn a worker for a task using wiggum-start
# Sets: SPAWNED_WORKER_ID, SPAWNED_WORKER_PID (for caller to use)
spawn_worker() {
    local task_id="$1"

    # Use wiggum-start to start the worker, capturing exit code
    local start_output
    local start_exit_code
    start_output=$("$WIGGUM_HOME/bin/wiggum-start" "$task_id" \
        --max-iters "$MAX_ITERATIONS" --max-turns "$MAX_TURNS" \
        --agent-type "$AGENT_TYPE" 2>&1) || start_exit_code=$?
    start_exit_code=${start_exit_code:-0}

    # Handle specific exit codes
    if [ "$start_exit_code" -eq "$EXIT_WORKER_ALREADY_EXISTS" ]; then
        # Worker directory exists from previous run
        # Exclude plan workers (worker-TASK-xxx-plan-*) - those are read-only planning sessions
        local existing_dir
        existing_dir=$(find_any_worker_by_task_id "$RALPH_DIR" "$task_id" | grep -v -- '-plan-' || true)
        if [ -n "$existing_dir" ]; then
            # Check if the worker process is still running
            local stale_pid
            stale_pid=$(cat "$existing_dir/agent.pid" 2>/dev/null || true)
            if [ -n "$stale_pid" ] && kill -0 "$stale_pid" 2>/dev/null; then
                # Process is still running, refuse to spawn duplicate
                log_error "Worker for $task_id is still running (PID: $stale_pid)"
                log_error "Use 'wiggum stop $task_id' or 'wiggum kill $task_id' first"
                return 1
            fi
            # Process not running - check if it's resumable
            if ! _is_terminal_failure "$existing_dir"; then
                # Worker is resumable - let resume logic handle it
                log "Worker for $task_id is resumable, skipping spawn"
                return 1
            fi
            # Terminal failure - clean up and retry fresh
            log "Cleaning up terminal-failure worker for $task_id: $(basename "$existing_dir")"
            rm -rf "$existing_dir"
            # Retry spawning - reset exit code first
            start_exit_code=0
            start_output=$("$WIGGUM_HOME/bin/wiggum-start" "$task_id" \
                --max-iters "$MAX_ITERATIONS" --max-turns "$MAX_TURNS" \
                --agent-type "$AGENT_TYPE" 2>&1) || start_exit_code=$?
        fi
    fi

    # Check if spawn succeeded
    if [ "$start_exit_code" -ne 0 ]; then
        log_error "wiggum start failed (exit $start_exit_code): $start_output"
        return 1
    fi

    # Find the worker directory that was just created (using shared library)
    local worker_dir
    worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$task_id")

    if [ -z "$worker_dir" ]; then
        log_error "Failed to find worker directory for $task_id"
        return 1
    fi

    SPAWNED_WORKER_ID=$(basename "$worker_dir")

    # Wait for agent.pid to appear (using shared library)
    if ! wait_for_worker_pid "$worker_dir" "$PID_WAIT_TIMEOUT"; then
        log_error "Agent PID file not created for $task_id"
        return 1
    fi

    SPAWNED_WORKER_PID=$(cat "$worker_dir/agent.pid")
    activity_log "worker.spawned" "$SPAWNED_WORKER_ID" "$task_id" "pid=$SPAWNED_WORKER_PID"
}

# Run periodic sync to update PR statuses and detect new comments
run_periodic_sync() {
    # Call wiggum review sync and capture output
    local sync_output sync_exit=0
    sync_output=$("$WIGGUM_HOME/bin/wiggum-review" sync 2>&1) || sync_exit=$?

    if [ $sync_exit -ne 0 ]; then
        log_error "Periodic sync failed"
        echo "$sync_output" | sed 's/^/  [sync] /'
        return
    fi

    # Parse sync results - only show output if something happened
    local merged_count comments_count
    merged_count=$(echo "$sync_output" | sed -n 's/.*Merged PRs updated: \([0-9]*\).*/\1/p' | head -1)
    comments_count=$(echo "$sync_output" | sed -n 's/.*Tasks with new comments: \([0-9]*\).*/\1/p' | head -1)
    merged_count=${merged_count:-0}
    comments_count=${comments_count:-0}

    if [ "$comments_count" -gt 0 ]; then
        log "PR sync: $comments_count task(s) with new comments"
        echo "$sync_output" | sed 's/^/  [sync] /'

        # Check for tasks needing fixes
        local tasks_needing_fix="$RALPH_DIR/.tasks-needing-fix.txt"
        if [ -s "$tasks_needing_fix" ]; then
            log "Tasks need comment fixes - will spawn fix workers"
        fi
    fi
}

# Pre-worker checks before spawning a new worker
# Returns 0 if safe to proceed, 1 if conflicts detected
pre_worker_checks() {
    # Pull latest changes from main with retry
    log "Pulling latest changes from origin/main..."

    local pull_output
    local max_attempts=3
    local delays=(2 4)

    for ((attempt=1; attempt<=max_attempts; attempt++)); do
        if pull_output=$(git pull --ff-only origin main 2>&1); then
            break
        fi

        # Immediately fail on conflicts (non-transient)
        if echo "$pull_output" | grep -qi "CONFLICT"; then
            log_error "Git pull conflict detected: $pull_output"
            log_error "Cannot spawn new workers with unresolved conflicts"
            return 1
        fi

        # On last attempt, give up
        if [ $attempt -eq $max_attempts ]; then
            log_error "Git pull failed after $max_attempts attempts: $pull_output"
            return 1
        fi

        # Transient error - retry with backoff
        local delay=${delays[$((attempt-1))]}
        log "Git pull attempt $attempt failed (transient), retrying in ${delay}s..."
        sleep "$delay"
    done

    # Check for conflicts with active worktrees
    local workers_dir="$RALPH_DIR/workers"
    if [ -d "$workers_dir" ]; then
        for worker_dir in "$workers_dir"/worker-*; do
            [ -d "$worker_dir/workspace" ] || continue

            local workspace="$worker_dir/workspace"
            if [ -d "$workspace/.git" ] || [ -f "$workspace/.git" ]; then
                # Check if worktree has conflicts with main
                if git -C "$workspace" diff --name-only origin/main 2>/dev/null | \
                   xargs -I {} git -C "$workspace" diff --check origin/main -- {} 2>&1 | \
                   grep -q "conflict"; then
                    log_error "Conflict detected in $(basename "$worker_dir")"
                    return 1
                fi
            fi
        done
    fi

    return 0
}

# Handle main worker completion (callback for pool_cleanup_finished)
_handle_main_worker_completion() {
    local worker_dir="$1"
    local task_id="$2"
    activity_log "worker.completed" "" "$task_id" "worker_dir=$worker_dir"
    log "Worker for $task_id finished"
    scheduler_mark_event
}

# Handle fix worker completion (callback for pool_cleanup_finished)
_handle_fix_worker_completion() {
    local worker_dir="$1"
    local task_id="$2"

    if handle_fix_worker_completion "$worker_dir" "$task_id"; then
        # Fix succeeded - attempt merge if needed
        if git_state_is "$worker_dir" "needs_merge"; then
            attempt_pr_merge "$worker_dir" "$task_id" "$RALPH_DIR" || true
        fi
    fi
}

# Handle fix worker timeout (callback for pool_cleanup_finished)
_handle_fix_worker_timeout() {
    local worker_dir="$1"
    local task_id="$2"
    handle_fix_worker_timeout "$worker_dir" "$task_id" "$FIX_WORKER_TIMEOUT"
}

# Handle resolve worker completion (callback for pool_cleanup_finished)
_handle_resolve_worker_completion() {
    local worker_dir="$1"
    local task_id="$2"

    if handle_resolve_worker_completion "$worker_dir" "$task_id"; then
        # Resolution succeeded - attempt merge if needed
        if git_state_is "$worker_dir" "needs_merge"; then
            attempt_pr_merge "$worker_dir" "$task_id" "$RALPH_DIR" || true
        fi

        # If this was a batch worker, immediately spawn the next one
        _spawn_next_batch_worker "$worker_dir" || true
    fi
}

# Spawn the next worker in a batch queue (for back-to-back execution)
#
# Called after a batch worker completes to immediately trigger the next one.
# Returns 0 if a worker was spawned, 1 if batch is complete/failed/no next worker.
_spawn_next_batch_worker() {
    local completed_worker_dir="$1"

    # Check if this was a batch worker
    source "$WIGGUM_HOME/lib/scheduler/batch-coordination.sh"
    batch_coord_has_worker_context "$completed_worker_dir" || return 1

    local batch_id
    batch_id=$(batch_coord_read_worker_context "$completed_worker_dir" "batch_id")
    [ -n "$batch_id" ] || return 1

    # Check batch status
    local status
    status=$(batch_coord_get_status "$batch_id" "$PROJECT_DIR")
    case "$status" in
        complete|failed) return 1 ;;
    esac

    # Find the next worker that should execute
    local next_task_id
    next_task_id=$(batch_coord_get_next_task "$batch_id" "$PROJECT_DIR")
    [ -n "$next_task_id" ] || return 1

    # Find worker directory for next task
    local next_worker_dir
    next_worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$next_task_id" 2>/dev/null)
    [ -n "$next_worker_dir" ] && [ -d "$next_worker_dir" ] || return 1

    # Verify it's this task's turn and it needs resolution
    git_state_is "$next_worker_dir" "needs_resolve" || return 1
    batch_coord_is_my_turn "$batch_id" "$next_task_id" "$PROJECT_DIR" || return 1

    # Check priority worker capacity
    local fix_count resolve_count total_priority
    fix_count=$(pool_count "fix")
    resolve_count=$(pool_count "resolve")
    total_priority=$((fix_count + resolve_count))
    if [ "$total_priority" -ge "$FIX_WORKER_LIMIT" ]; then
        log "Batch: deferring next worker - at capacity ($total_priority/$FIX_WORKER_LIMIT)"
        return 1
    fi

    log "Batch $batch_id: immediately spawning next worker for $next_task_id"

    # Use the existing spawn function from priority-workers.sh
    source "$WIGGUM_HOME/lib/scheduler/priority-workers.sh"
    _spawn_batch_resolve_worker "$RALPH_DIR" "$PROJECT_DIR" "$next_worker_dir" "$next_task_id"
    return $?
}

# Handle resolve worker timeout (callback for pool_cleanup_finished)
_handle_resolve_worker_timeout() {
    local worker_dir="$1"
    local task_id="$2"
    handle_resolve_worker_timeout "$worker_dir" "$task_id" "$RESOLVE_WORKER_TIMEOUT"
}

# Check for completed multi-PR planners and process their results
_check_completed_planners() {
    for planner_dir in "$RALPH_DIR/workers"/planner-batch-*; do
        [ -d "$planner_dir" ] || continue

        local batch_id
        batch_id=$(basename "$planner_dir" | sed 's/^planner-//')

        # Skip if not in planning status
        local status
        status=$(conflict_queue_get_batch_status "$RALPH_DIR" "$batch_id" 2>/dev/null || echo "unknown")
        [ "$status" = "planning" ] || continue

        # Check if planner is still running
        local pid_file="$planner_dir/planner.pid"
        if [ -f "$pid_file" ]; then
            local pid
            pid=$(cat "$pid_file")
            if kill -0 "$pid" 2>/dev/null; then
                continue  # Still running
            fi
        fi

        # Planner finished - check result
        local result_file
        result_file=$(find "$planner_dir/results" -name "*-result.json" 2>/dev/null | head -1)

        if [ -n "$result_file" ] && [ -f "$result_file" ]; then
            local gate_result
            gate_result=$(jq -r '.outputs.gate_result // "FAIL"' "$result_file")

            if [ "$gate_result" = "PASS" ]; then
                conflict_queue_update_batch_status "$RALPH_DIR" "$batch_id" "planned"
                log "Multi-PR planning completed for batch $batch_id"

                # Mark individual workers as ready for resolution with plan
                local task_ids
                task_ids=$(conflict_queue_get_batch_tasks "$RALPH_DIR" "$batch_id")
                while read -r task_id; do
                    [ -n "$task_id" ] || continue
                    local worker_dir
                    worker_dir=$(find_worker_by_task_id "$RALPH_DIR" "$task_id" 2>/dev/null)
                    if [ -n "$worker_dir" ] && [ -d "$worker_dir" ]; then
                        # Skip workers already in terminal states (merged, failed)
                        # or workers whose workspace was already cleaned up
                        local current_state
                        current_state=$(git_state_get "$worker_dir" 2>/dev/null || echo "unknown")
                        if [[ "$current_state" == "merged" || "$current_state" == "failed" ]]; then
                            log "Skipping $task_id - already in terminal state: $current_state"
                            continue
                        fi
                        if [ ! -d "$worker_dir/workspace" ]; then
                            # Verify actual merge status instead of guessing
                            local kanban_status pr_status="unknown"
                            kanban_status=$(grep -E "^\- \[.\] \*\*\[$task_id\]" "$RALPH_DIR/kanban.md" 2>/dev/null | \
                                sed 's/^- \[\(.\)\].*/\1/' | head -1 || echo "")

                            if [ "$kanban_status" = "x" ]; then
                                log "Skipping $task_id - PR is merged (workspace cleaned up)"
                            else
                                # Check GitHub if kanban doesn't show merged
                                local pr_number
                                pr_number=$(git_state_get_pr "$worker_dir" 2>/dev/null || echo "")
                                if [ -n "$pr_number" ] && [ "$pr_number" != "null" ]; then
                                    pr_status=$(timeout "${WIGGUM_GH_TIMEOUT:-10}" gh pr view "$pr_number" --json state -q '.state' 2>/dev/null || echo "UNKNOWN")
                                fi
                                if [ "$pr_status" = "MERGED" ]; then
                                    log "Skipping $task_id - PR #$pr_number is merged (workspace cleaned up)"
                                else
                                    log_warn "Skipping $task_id - workspace missing (kanban: $kanban_status, PR: $pr_status)"
                                fi
                            fi
                            continue
                        fi
                        git_state_set "$worker_dir" "needs_resolve" "wiggum-run._check_completed_planners" "Resolution plan ready"
                    fi
                done <<< "$task_ids"
            else
                conflict_queue_update_batch_status "$RALPH_DIR" "$batch_id" "failed"
                log_error "Multi-PR planning failed for batch $batch_id"
            fi
        else
            # No result file - check if planner ran at all
            if [ -f "$pid_file" ]; then
                log_warn "Multi-PR planner for $batch_id exited without result"
                conflict_queue_update_batch_status "$RALPH_DIR" "$batch_id" "failed"
            fi
        fi
    done
}

# Check for conflict batches and spawn multi-PR planner if needed (non-blocking)
_check_and_spawn_multi_pr_planner() {
    # First, check for completed planners
    _check_completed_planners

    # Initialize conflict queue if needed
    conflict_queue_init "$RALPH_DIR"

    # Check if a planner is already running
    for planner_dir in "$RALPH_DIR/workers"/planner-batch-*; do
        [ -d "$planner_dir" ] || continue
        local pid_file="$planner_dir/planner.pid"
        if [ -f "$pid_file" ]; then
            local pid
            pid=$(cat "$pid_file")
            if kill -0 "$pid" 2>/dev/null; then
                return 0  # Planner already running, don't spawn another
            fi
        fi
    done

    local batch_id task_ids

    # First, check for existing "pending" batches (created by Phase 5 of PR merge optimizer)
    local queue_file="$RALPH_DIR/batches/queue.json"
    if [ -f "$queue_file" ]; then
        batch_id=$(jq -r '[.batches | to_entries[] | select(.value.status == "pending")] | .[0].key // empty' "$queue_file")
        if [ -n "$batch_id" ]; then
            task_ids=$(jq -r --arg b "$batch_id" '.batches[$b].task_ids' "$queue_file")
            log "Found pending batch $batch_id ready for planning"
        fi
    fi

    # If no pending batch, try grouping unbatched tasks (legacy flow)
    if [ -z "$batch_id" ]; then
        # Check if any unbatched tasks can be grouped
        if ! conflict_queue_batch_ready "$RALPH_DIR"; then
            return 0
        fi

        # Get groups of related conflicts
        local groups
        groups=$(conflict_queue_group_related "$RALPH_DIR")

        local group_count
        group_count=$(echo "$groups" | jq 'length')

        if [ "$group_count" -eq 0 ]; then
            return 0
        fi

        log "Found $group_count conflict group(s) ready for coordinated planning"

        # Process first ready group
        local first_group
        first_group=$(echo "$groups" | jq '.[0]')
        task_ids=$(echo "$first_group" | jq '.task_ids')

        # Create batch
        batch_id=$(conflict_queue_create_batch "$RALPH_DIR" "$task_ids")
        local task_count
        task_count=$(echo "$task_ids" | jq 'length')
        log "Created conflict batch $batch_id with $task_count tasks"
    fi

    # Create planner worker directory
    local planner_worker_dir="$RALPH_DIR/workers/planner-$batch_id"
    mkdir -p "$planner_worker_dir/logs" "$planner_worker_dir/results"

    # Build batch file
    conflict_queue_build_batch_file "$RALPH_DIR" "$batch_id" "$planner_worker_dir/conflict-batch.json"

    # Update batch status
    conflict_queue_update_batch_status "$RALPH_DIR" "$batch_id" "planning"

    log "Spawning multi-PR planner for batch $batch_id (non-blocking)"

    # Launch planner agent in background
    (
        cd "$PROJECT_DIR" || exit 1
        export WIGGUM_HOME
        source "$WIGGUM_HOME/lib/worker/agent-registry.sh"
        run_agent "workflow.multi-pr-planner" "$planner_worker_dir" "$PROJECT_DIR" 0
    ) >> "$RALPH_DIR/logs/planner.log" 2>&1 &

    local planner_pid=$!
    echo "$planner_pid" > "$planner_worker_dir/planner.pid"

    log "Multi-PR planner spawned (PID: $planner_pid) - will check results on next cycle"
}

# Schedule resume of stopped workers
#
# Called once at startup to resume any stopped workers before starting new
# tasks. Delegates to `wiggum resume` which handles the logic of determining
# whether to use LLM analysis (step completed) or direct resume (interrupted).
#
# Skips workers that:
#   - Are terminal failures (last step + FAIL)
#   - Are at capacity (MAX_WORKERS)
#   - Have tasks no longer pending/in-progress
_schedule_resume_workers() {
    local resumable
    resumable=$(get_resumable_workers "$RALPH_DIR")
    [ -n "$resumable" ] || return 0

    log "Checking for stopped workers to resume..."

    while read -r worker_dir task_id current_step worker_type; do
        [ -n "$worker_dir" ] || continue

        # Check capacity based on worker type
        if [[ "$worker_type" == "fix" || "$worker_type" == "resolve" ]]; then
            local fix_count resolve_count total_priority
            fix_count=$(pool_count "fix")
            resolve_count=$(pool_count "resolve")
            total_priority=$((fix_count + resolve_count))
            if [ "$total_priority" -ge "$FIX_WORKER_LIMIT" ]; then
                log "Priority workers at capacity ($total_priority/$FIX_WORKER_LIMIT) - deferring resume of $task_id"
                continue
            fi
        else
            local main_count
            main_count=$(pool_count "main")
            if [ "$main_count" -ge "$MAX_WORKERS" ]; then
                log "At capacity ($main_count/$MAX_WORKERS) - deferring remaining resumes"
                break
            fi
        fi

        # Check task is still pending or in-progress
        local task_status
        task_status=$(get_task_status "$RALPH_DIR/kanban.md" "$task_id")
        case "$task_status" in
            " "|"=") ;;
            *)
                log_debug "Skipping resume of $task_id - task status is '$task_status'"
                continue
                ;;
        esac

        # Mark as in-progress if pending
        if [ "$task_status" = " " ]; then
            if ! update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "="; then
                log_error "Failed to mark $task_id as in-progress"
                continue
            fi
        fi

        # Resume the worker via wiggum resume (handles interrupted vs completed logic)
        # Note: resume-decide may determine a different starting step based on analysis
        log "Initiating resume for $task_id (pipeline at: '$current_step')"
        local worker_id
        worker_id=$(basename "$worker_dir")

        # Run wiggum resume in background, passing through config
        # --quiet suppresses interactive output
        (
            cd "$PROJECT_DIR" && \
            "$WIGGUM_HOME/bin/wiggum-resume" "$worker_id" --quiet \
                --max-iters "$MAX_ITERATIONS" \
                --max-turns "$MAX_TURNS" \
                ${WIGGUM_PIPELINE:+--pipeline "$WIGGUM_PIPELINE"}
        ) >> "$RALPH_DIR/logs/workers.log" 2>&1 &

        # Track the worker
        if wait_for_worker_pid "$worker_dir" "$PID_WAIT_TIMEOUT"; then
            local pid
            pid=$(cat "$worker_dir/agent.pid")
            pool_add "$pid" "$worker_type" "$task_id"
            scheduler_mark_event
            activity_log "worker.resumed" "$(basename "$worker_dir")" "$task_id" "pipeline_step=$current_step pid=$pid type=$worker_type"
            log "Resumed worker for $task_id (PID: $pid, type: $worker_type)"
        else
            log_error "Resume started but PID not created for $task_id"
        fi
    done <<< "$resumable"
}

# Check if copilot has reviewed a PR
#
# Args:
#   worker_dir - Worker directory path
#
# Returns: 0 if copilot has reviewed, 1 otherwise
_has_copilot_review() {
    local worker_dir="$1"
    local task_id
    task_id=$(get_task_id_from_worker "$(basename "$worker_dir")")
    local comments_file="$worker_dir/task-comments.md"

    [ -f "$comments_file" ] || return 1

    # Check for Copilot author (case insensitive)
    grep -qi '^\*\*Author:\*\* Copilot' "$comments_file"
}

# Check if there are NEW comments after the last push
#
# Args:
#   worker_dir - Worker directory path
#
# Returns: 0 if new comments exist, 1 otherwise
# Outputs: Count of new comments if any exist
_has_new_comments() {
    local worker_dir="$1"
    local comments_file="$worker_dir/task-comments.md"

    [ -f "$comments_file" ] || return 1

    local last_push
    last_push=$(git_state_get_last_push "$worker_dir")

    # If no last push recorded, all comments are "new"
    if [ "$last_push" = "null" ] || [ -z "$last_push" ]; then
        # Check if any comments exist at all
        if grep -q '^\*\*Date:\*\*' "$comments_file"; then
            local count
            count=$(grep -c '^\*\*Date:\*\*' "$comments_file" || true)
            echo "$count"
            return 0
        fi
        return 1
    fi

    # Convert last_push to comparable timestamp (seconds since epoch)
    local last_push_epoch
    last_push_epoch=$(date -d "$last_push" +%s 2>/dev/null || echo "0")

    # Extract comment dates and compare
    local new_count=0
    while IFS= read -r date_line; do
        # Extract timestamp from "**Date:** 2026-01-27T03:10:28Z"
        local comment_date
        comment_date=$(echo "$date_line" | sed 's/\*\*Date:\*\* //')
        local comment_epoch
        comment_epoch=$(date -d "$comment_date" +%s 2>/dev/null || echo "0")

        if [ "$comment_epoch" -gt "$last_push_epoch" ]; then
            ((++new_count))
        fi
    done < <(grep '^\*\*Date:\*\*' "$comments_file" 2>/dev/null || true)

    if [ "$new_count" -gt 0 ]; then
        echo "$new_count"
        return 0
    fi
    return 1
}

# Check if PR has merge conflicts with main
#
# Args:
#   worker_dir - Worker directory path
#
# Returns: 0 if conflicts exist, 1 otherwise
# Outputs: Newline-separated list of conflicting files
_check_merge_conflicts() {
    local worker_dir="$1"
    local workspace="$worker_dir/workspace"

    [ -d "$workspace" ] || return 1

    # Fetch latest from origin
    git -C "$workspace" fetch origin main 2>/dev/null || true

    # Try a dry-run merge to detect conflicts
    local merge_output
    if ! merge_output=$(git -C "$workspace" merge-tree "$(git -C "$workspace" merge-base HEAD origin/main)" HEAD origin/main 2>&1); then
        # merge-tree failed, try alternative method
        :
    fi

    # Check for conflict markers in merge-tree output
    if echo "$merge_output" | grep -q '^<<<<<<<'; then
        # Extract conflicting files
        echo "$merge_output" | grep -E '^\+\+\+|^changed in' | sed 's/^+++ //' | sed 's/^changed in .* //'
        return 0
    fi

    # Alternative: try actual merge with abort
    (
        cd "$workspace" || exit 1
        git stash -q 2>/dev/null || true
        if ! git merge --no-commit --no-ff origin/main 2>/dev/null; then
            # Get list of unmerged files
            git diff --name-only --diff-filter=U 2>/dev/null
            git merge --abort 2>/dev/null || true
            git stash pop -q 2>/dev/null || true
            exit 0
        fi
        git merge --abort 2>/dev/null || true
        git stash pop -q 2>/dev/null || true
        exit 1
    )
}

# Attempt to merge a PR immediately
#
# Args:
#   task_id   - Task identifier
#   pr_number - PR number
#
# Returns: 0 on success, 1 on failure
_try_merge_pr() {
    local task_id="$1"
    local pr_number="$2"

    log "  Attempting merge for $task_id (PR #$pr_number)..."

    if gh pr merge "$pr_number" --squash --auto 2>/dev/null; then
        log "  ✓ Merge initiated for $task_id"
        return 0
    else
        log "  ✗ Merge failed for $task_id"
        return 1
    fi
}

# =============================================================================
# Service-Based Main Loop
# =============================================================================

# Initialize and run the main orchestration loop
#
# Uses declarative service definitions from config/services.json. Each
# orchestrator responsibility is defined as a "service" with its own
# interval and execution config.
#
# Benefits:
# - Configurable intervals per service (not hardcoded)
# - Add new periodic tasks without modifying core loop
# - Services can be enabled/disabled per-project via .ralph/services.json
# - Better observability via `wiggum service status`
_main_loop() {
    log "Starting service-based scheduler"

    # Load service configuration
    local config_file="$WIGGUM_HOME/config/services.json"
    if [ -f "$config_file" ]; then
        if ! service_load "$config_file" 2>/dev/null; then
            log_warn "Failed to load services.json, using builtin defaults"
            service_load_builtin_defaults
        fi
    else
        log_warn "No services.json found, using builtin defaults"
        service_load_builtin_defaults
    fi

    # Load project-specific overrides
    if [ -f "$RALPH_DIR/services.json" ]; then
        log "Loading project service overrides from .ralph/services.json"
        service_load_override "$RALPH_DIR/services.json" 2>/dev/null || true
    fi

    # Initialize service state (persists across restarts)
    service_state_init "$RALPH_DIR"
    service_state_restore 2>/dev/null || true

    # Initialize service runner
    service_runner_init "$RALPH_DIR" "$PROJECT_DIR"

    # Initialize service scheduler
    service_scheduler_init "$RALPH_DIR" "$PROJECT_DIR"

    log "Loaded $(service_count) services"

    local iteration=0

    # Service-based main loop
    while true; do
        ((++iteration))

        # Clean up finished workers FIRST - before services run
        # This ensures completion handlers run before services detect "stuck" workers
        # (e.g., resolve-workers service checks agent.pid which is deleted on completion)
        pool_cleanup_finished "main" 0 _handle_main_worker_completion ""
        pool_cleanup_finished "fix" "$FIX_WORKER_TIMEOUT" _handle_fix_worker_completion _handle_fix_worker_timeout
        pool_cleanup_finished "resolve" "$RESOLVE_WORKER_TIMEOUT" _handle_resolve_worker_completion _handle_resolve_worker_timeout

        # Run scheduler tick - executes any due services
        # (startup services are run automatically on first tick)
        service_scheduler_tick

        # Check if we're done
        if scheduler_is_complete; then
            display_final_summary "$RALPH_DIR"
            break
        fi

        # Check rate limit before spawning
        if rate_limit_check "$RALPH_DIR"; then
            local cycle_prompts
            cycle_prompts=$(jq -r '.current_5h_cycle.total_prompts // 0' "$RALPH_DIR/claude-usage.json" 2>/dev/null)
            log "Rate limit threshold reached ($cycle_prompts >= $WIGGUM_RATE_LIMIT_THRESHOLD prompts in 5h cycle)"
            activity_log "rate_limit.detected" "" "" "prompts=$cycle_prompts threshold=$WIGGUM_RATE_LIMIT_THRESHOLD"
            rate_limit_wait_for_cycle_reset
            activity_log "rate_limit.resumed" "" ""
            usage_tracker_write_shared "$RALPH_DIR" > /dev/null 2>&1 || true
            continue
        fi

        # Update in-memory scheduler state and spawn workers
        # NOTE: Task spawning MUST run in the main process because it depends on
        # in-memory state ($SCHED_READY_TASKS) that is not accessible from subshells.
        # The task-spawner service is disabled/no-op because services run in subshells.
        scheduler_tick

        # Debug: show ready tasks (only when there are some)
        if [ -n "$SCHED_READY_TASKS" ]; then
            log_debug "Ready tasks: $SCHED_READY_TASKS"
        fi

        # Spawn workers for ready tasks (directly in main process, not via service)
        for task_id in $SCHED_READY_TASKS; do
            # Check if we can spawn this task
            if ! scheduler_can_spawn_task "$task_id" "$MAX_WORKERS"; then
                case "$SCHED_SKIP_REASON" in
                    at_capacity) break ;;  # Stop trying when at capacity
                    file_conflict)
                        # Build conflict info for logging
                        local -A _temp_workers=()
                        _build_workers() {
                            local pid="$1" type="$2" tid="$3"
                            [ "$type" = "main" ] && _temp_workers[$pid]="$tid"
                        }
                        pool_foreach "main" _build_workers
                        local conflicts
                        conflicts=$(get_conflicting_files "$RALPH_DIR" "$task_id" _temp_workers | tr '\n' ',' | sed 's/,$//')
                        log "Deferring $task_id - file conflict: $conflicts"
                        ;;
                    *) ;;  # Skip silently for cyclic_dependency, skip_count
                esac
                continue
            fi

            # Run pre-worker checks (git pull, conflict detection)
            if ! pre_worker_checks; then
                log_error "Pre-worker checks failed for $task_id - skipping this task"
                continue
            fi

            # Get task priority for logging
            local task_priority
            task_priority=$(get_task_priority "$RALPH_DIR/kanban.md" "$task_id")

            # Mark task as in-progress in kanban
            log "Assigning $task_id (Priority: ${task_priority:-MEDIUM}) to new worker"
            if ! update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "="; then
                log_error "Failed to mark $task_id as in-progress"
                scheduler_increment_skip "$task_id"
                local skip_count
                skip_count=$(scheduler_get_skip_count "$task_id")
                log "Task $task_id skip count: $skip_count/$MAX_SKIP_RETRIES"
                if [ "$skip_count" -ge "$MAX_SKIP_RETRIES" ]; then
                    log_error "Task $task_id permanently skipped after $MAX_SKIP_RETRIES consecutive kanban failures"
                fi
                continue
            fi

            # Spawn worker (wiggum-start handles backgrounding)
            if ! spawn_worker "$task_id"; then
                log_error "Failed to spawn worker for $task_id"
                update_kanban_status "$RALPH_DIR/kanban.md" "$task_id" "*"
                continue
            fi

            pool_add "$SPAWNED_WORKER_PID" "main" "$task_id"
            scheduler_mark_event

            # Remove from ready-since tracking (task is no longer waiting)
            scheduler_remove_from_aging "$task_id"

            # Log task assignment to audit log
            audit_log_task_assigned "$task_id" "$SPAWNED_WORKER_ID" "$SPAWNED_WORKER_PID"

            log "Spawned worker $SPAWNED_WORKER_ID for $task_id (PID: $SPAWNED_WORKER_PID)"
        done

        # Periodically decay skip counts (every ~3 minutes at 1s sleep)
        if (( iteration % 180 == 0 )); then
            scheduler_decay_skip_counts
        fi

        # Periodically detect orphan workers (every ~1 minute at 1s sleep)
        if (( iteration % 60 == 0 )); then
            scheduler_detect_orphan_workers
        fi

        scheduler_update_aging

        if [ "$SCHED_SCHEDULING_EVENT" = true ]; then
            local cyclic_ref
            cyclic_ref=$(scheduler_get_cyclic_tasks_ref)
            display_orchestrator_status \
                "$iteration" \
                "$MAX_WORKERS" \
                "$SCHED_READY_TASKS" \
                "$SCHED_BLOCKED_TASKS" \
                "$cyclic_ref" \
                "$RALPH_DIR" \
                "$(scheduler_get_ready_since_file)" \
                "$AGING_FACTOR" \
                "$PLAN_BONUS" \
                "$DEP_BONUS_PER_TASK"
        fi

        # Persist service state periodically
        service_state_save 2>/dev/null || true

        # Wait before next iteration (1 second for finer-grained service timing)
        sleep 1
    done

    # Final state save
    service_state_save 2>/dev/null || true
}

main() {
    # Parse verbose flags first
    parse_verbose_flags "$@"
    set -- "${WIGGUM_REMAINING_ARGS[@]}"

    # Parse run options
    while [[ $# -gt 0 ]]; do
        case "$1" in
            plan)
                export WIGGUM_PLAN_MODE=true
                shift
                ;;
            --max-workers)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-workers requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_WORKERS="$2"
                shift 2
                ;;
            --max-iters)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-iters requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_ITERATIONS="$2"
                shift 2
                ;;
            --max-turns)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --max-turns requires a number argument"
                    exit $EXIT_USAGE
                fi
                MAX_TURNS="$2"
                shift 2
                ;;
            --fix-agents)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --fix-agents requires a number argument"
                    exit $EXIT_USAGE
                fi
                FIX_WORKER_LIMIT="$2"
                shift 2
                ;;
            --pipeline)
                if [[ -z "${2:-}" ]] || [[ "${2:-}" =~ ^- ]]; then
                    echo "Error: --pipeline requires a name argument"
                    exit $EXIT_USAGE
                fi
                export WIGGUM_PIPELINE="$2"
                shift 2
                ;;
            --force)
                FORCE_LOCK=true
                shift
                ;;
            -h|--help)
                show_help
                exit $EXIT_OK
                ;;
            -*)
                echo "Unknown option: $1"
                echo ""
                show_help
                exit $EXIT_USAGE
                ;;
            *)
                echo "Unknown argument: $1"
                echo ""
                show_help
                exit $EXIT_USAGE
                ;;
        esac
    done

    # Initialize project if needed
    if [ ! -d "$RALPH_DIR" ]; then
        log_error ".ralph/ directory not found. Run 'wiggum init' first."
        exit $EXIT_RUN_NO_RALPH_DIR
    fi

    # Ensure logs directory exists and set up file logging
    mkdir -p "$RALPH_DIR/logs"
    export LOG_FILE="$RALPH_DIR/logs/orchestrator.log"
    log "Orchestrator log: $LOG_FILE"

    # Load rate limit configuration
    load_rate_limit_config

    # Load workers configuration (fix_worker_limit)
    load_workers_config
    # CLI --fix-agents takes precedence over config
    FIX_WORKER_LIMIT="${FIX_WORKER_LIMIT:-$WIGGUM_FIX_WORKER_LIMIT}"

    # Initialize activity log
    activity_init "$PROJECT_DIR"

    # Ensure only one orchestrator runs at a time (not local - needed by trap handler)
    orchestrator_lock="$RALPH_DIR/.orchestrator.pid"

    # Check if another orchestrator is already running
    if [ -f "$orchestrator_lock" ]; then
        local existing_pid
        existing_pid=$(cat "$orchestrator_lock" 2>/dev/null)

        # Validate PID is a number
        if [[ "$existing_pid" =~ ^[0-9]+$ ]]; then
            # Check if that process is still running and is wiggum-run
            if kill -0 "$existing_pid" 2>/dev/null; then
                if ps -p "$existing_pid" -o args= 2>/dev/null | grep -q "wiggum-run"; then
                    if [ "$FORCE_LOCK" = true ]; then
                        log "WARNING: Overriding lock held by running orchestrator (PID: $existing_pid) due to --force"
                        rm -f "$orchestrator_lock"
                    else
                        log_error "Another wiggum-run orchestrator is already running (PID: $existing_pid)"
                        echo ""
                        echo "Only one orchestrator can run at a time to prevent conflicts."
                        echo "If you're sure no orchestrator is running, remove: $orchestrator_lock"
                        echo "Or use --force to override the lock."
                        exit $EXIT_RUN_ORCHESTRATOR_RUNNING
                    fi
                else
                    # PID exists but it's not wiggum-run (PID reused)
                    log "Cleaning stale orchestrator lock (PID reused)"
                    rm -f "$orchestrator_lock"
                fi
            else
                # Process no longer running
                log "Cleaning stale orchestrator lock"
                rm -f "$orchestrator_lock"
            fi
        else
            # Invalid PID in lock file
            log "Cleaning invalid orchestrator lock"
            rm -f "$orchestrator_lock"
        fi
    fi

    # Create orchestrator lock file
    echo "$$" > "$orchestrator_lock"
    log "Created orchestrator lock (PID: $$)"

    # Track shutdown state (not local - needed by trap handlers)
    _ORCH_SHUTDOWN_REQUESTED=false

    # Setup trap to cleanup lock file on exit
    cleanup_orchestrator() {
        if [ "${_ORCH_SHUTDOWN_REQUESTED:-false}" = false ]; then
            log "Cleaning up orchestrator lock"
            _ORCH_SHUTDOWN_REQUESTED=true
            rm -f "$orchestrator_lock"
        fi
    }
    trap cleanup_orchestrator EXIT

    # Handle INT and TERM signals - stop orchestration but leave workers running
    handle_shutdown_signal() {
        log ""
        log "Shutdown signal received - stopping orchestrator"
        log "Active workers will continue running to completion"
        log "Use 'wiggum status' to monitor worker progress"
        cleanup_orchestrator
        exit $EXIT_SIGINT
    }
    trap handle_shutdown_signal INT TERM

    if [ ! -f "$RALPH_DIR/kanban.md" ]; then
        log_error ".ralph/kanban.md not found. Create a kanban file first."
        exit $EXIT_RUN_NO_KANBAN
    fi

    # Validate kanban format before running
    log "Validating kanban.md format..."
    if ! "$WIGGUM_HOME/bin/wiggum-validate" --quiet; then
        log_error "Kanban validation failed. Run 'wiggum validate' to see details."
        exit $EXIT_RUN_VALIDATION_FAILED
    fi
    log "Kanban validation passed"

    # Initialize scheduler
    scheduler_init "$RALPH_DIR" "$PROJECT_DIR" "$AGING_FACTOR" "$SIBLING_WIP_PENALTY" "$PLAN_BONUS" "$DEP_BONUS_PER_TASK"

    # Check for self and circular dependencies
    log "Checking for dependency cycles..."
    scheduler_detect_cycles || true

    # Check for clean git status
    if [ -n "$(git status --porcelain 2>/dev/null)" ]; then
        log_error "Git working directory is not clean. Please commit or stash your changes before running."
        echo ""
        echo "Uncommitted changes detected:"
        git status --short
        exit $EXIT_RUN_GIT_DIRTY
    fi

    # Pull latest changes from main before starting
    log "Pulling latest changes from origin/main..."
    if ! git pull --ff-only origin main 2>&1; then
        log_error "Git pull failed. Please resolve any issues before running."
        exit $EXIT_GIT
    fi

    # Pre-flight checks: Ensure SSH keys are cached and gh is authenticated
    log "Running pre-flight checks..."

    # Extract hostname from git remote
    local git_remote
    git_remote=$(git remote get-url origin 2>/dev/null)
    if [ -n "$git_remote" ]; then
        # Extract hostname from SSH URLs (git@github.com:user/repo.git or ssh://git@github.com/user/repo.git)
        local git_host=""
        if [[ "$git_remote" =~ ^git@([^:]+): ]]; then
            git_host="${BASH_REMATCH[1]}"
        elif [[ "$git_remote" =~ ^ssh://git@([^/]+)/ ]]; then
            git_host="${BASH_REMATCH[1]}"
        fi

        if [ -n "$git_host" ]; then
            echo "  → Testing SSH connection to $git_host..."
            local ssh_output
            ssh_output=$(ssh -T "git@$git_host" 2>&1) || true
            echo "$ssh_output" | head -5
            if ! echo "$ssh_output" | grep -qi "successfully authenticated"; then
                log_error "SSH test failed. Please ensure your SSH keys are set up and the agent is running."
                echo ""
                echo "Try running: ssh -T git@$git_host"
                exit $EXIT_RUN_SSH_FAILED
            fi
            echo "  ✓ SSH connection successful"
        fi
    fi

    # Test GitHub CLI authentication
    echo "  → Checking gh auth status..."
    if gh auth status &>/dev/null; then
        echo "  ✓ GitHub CLI authenticated"
    else
        log_error "gh auth check failed. Please log in with: gh auth login"
        echo ""
        echo "Try running: gh auth status"
        exit $EXIT_RUN_GH_AUTH_FAILED
    fi

    echo ""

    # Note: Failed tasks [*] are not auto-retried - they wait for manual intervention.
    # Use 'wiggum resume TASK-ID' or 'wiggum retry TASK-ID' to restart failed tasks.
    local failed_tasks
    failed_tasks=$(get_failed_tasks "$RALPH_DIR/kanban.md")
    if [ -n "$failed_tasks" ]; then
        local failed_count
        failed_count=$(echo "$failed_tasks" | wc -w)
        log "Found $failed_count failed task(s) - waiting (use 'wiggum resume/retry' to restart):"
        for task_id in $failed_tasks; do
            echo "  ⏸ $task_id"
        done
        echo ""
    fi

    local mode_desc="standard"
    if [ "${WIGGUM_PLAN_MODE:-false}" = "true" ]; then
        mode_desc="plan mode"
    fi
    if [ -n "${WIGGUM_PIPELINE:-}" ]; then
        mode_desc="$mode_desc, pipeline: $WIGGUM_PIPELINE"
    fi
    log "Starting Chief Wiggum in $PROJECT_DIR ($mode_desc, max $MAX_WORKERS concurrent workers)"
    echo ""
    echo "Press Ctrl+C to stop and view 'wiggum status' for details"
    echo "=========================================="
    echo ""

    # Restore active workers from existing worker directories
    scheduler_restore_workers

    # Resume any stopped WIP workers before starting new ones
    _schedule_resume_workers

    # Run service-based main loop
    _main_loop
}

main "$@"
